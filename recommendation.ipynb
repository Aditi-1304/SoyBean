{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import os\n",
    "from werkzeug.utils import secure_filename\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "import joblib\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy._core'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load the Random Forest model (assuming it's saved as 'rf_model.pkl')\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# rf_model = joblib.load('D:\\SoySoy\\SoyBean\\Models\\rf_model.pkl')\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     rf_model \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mSoySoy\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mSoyBean\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mModels\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mrf_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: Random Forest model file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrf_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found at the specified path.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle.py:658\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[0;32m    656\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[1;32m--> 658\u001b[0m             obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj, filename, mmap_mode)\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle.py:577\u001b[0m, in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    575\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 577\u001b[0m     obj \u001b[38;5;241m=\u001b[39m unpickler\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n\u001b[0;32m    579\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been generated with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib version less than 0.10. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease regenerate this pickle file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m                       \u001b[38;5;241m%\u001b[39m filename,\n\u001b[0;32m    583\u001b[0m                       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\Lib\\pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1211\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m-> 1213\u001b[0m         dispatch[key[\u001b[38;5;241m0\u001b[39m]](\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[0;32m   1215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\Lib\\pickle.py:1538\u001b[0m, in \u001b[0;36m_Unpickler.load_stack_global\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(module) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m   1537\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTACK_GLOBAL requires str\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_class(module, name))\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\Lib\\pickle.py:1580\u001b[0m, in \u001b[0;36m_Unpickler.find_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m   1578\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m _compat_pickle\u001b[38;5;241m.\u001b[39mIMPORT_MAPPING:\n\u001b[0;32m   1579\u001b[0m         module \u001b[38;5;241m=\u001b[39m _compat_pickle\u001b[38;5;241m.\u001b[39mIMPORT_MAPPING[module]\n\u001b[1;32m-> 1580\u001b[0m \u001b[38;5;28m__import__\u001b[39m(module, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m   1582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _getattribute(sys\u001b[38;5;241m.\u001b[39mmodules[module], name)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy._core'"
     ]
    }
   ],
   "source": [
    "# --- Load Pre-trained Models and Data (as provided in your code) ---\n",
    "# Load the pre-trained CNN model (MobileNetV2)\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "cnn_model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "# Load the Random Forest model (assuming it's saved as 'rf_model.pkl')\n",
    "try:\n",
    "    # rf_model = joblib.load('D:\\SoySoy\\SoyBean\\Models\\rf_model.pkl')\n",
    "    rf_model = joblib.load('D:\\\\SoySoy\\\\SoyBean\\\\Models\\\\rf_model.pkl')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Random Forest model file 'rf_model.pkl' not found at the specified path.\")\n",
    "    rf_model = None\n",
    "\n",
    "# Load saved features, labels, and class names\n",
    "try:\n",
    "    features = np.load('D:\\SoySoy\\SoyBean\\Models\\features.npy')\n",
    "    labels = np.load('D:\\SoySoy\\SoyBean\\Models\\labels.npy')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Features file 'features.npy' not found at the specified path.\")\n",
    "    features = None\n",
    "    labels = None\n",
    "\n",
    "try:\n",
    "    with open('D:\\SoySoy\\SoyBean\\Models\\class_names.json', 'r') as f:\n",
    "        class_names = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Class names file 'class_names.json' not found at the specified path.\")\n",
    "    class_names = None\n",
    "\n",
    "# --- Function to Extract Features from an Image using MobileNetV2 ---\n",
    "def extract_feature_from_image(img_path):\n",
    "    try:\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_preprocessed = preprocess_input(img_array)\n",
    "        features = cnn_model.predict(img_preprocessed)\n",
    "        return features.flatten()  # Flatten the feature vector\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features from image: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Function for Disease Severity Estimation using OpenCV ---\n",
    "def estimate_severity(img_path):\n",
    "    try:\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # Mask green leaf area\n",
    "        lower_green = np.array([25, 40, 40])\n",
    "        upper_green = np.array([90, 255, 255])\n",
    "        leaf_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "\n",
    "        # Mask brown/yellowish (diseased area approx.)\n",
    "        lower_brown = np.array([10, 50, 50])\n",
    "        upper_brown = np.array([30, 255, 255])\n",
    "        disease_mask = cv2.inRange(hsv, lower_brown, upper_brown)\n",
    "\n",
    "        # Only count disease pixels within the leaf\n",
    "        disease_in_leaf = cv2.bitwise_and(disease_mask, disease_mask, mask=leaf_mask)\n",
    "\n",
    "        total_leaf = np.count_nonzero(leaf_mask)\n",
    "        diseased_area = np.count_nonzero(disease_in_leaf)\n",
    "\n",
    "        if total_leaf == 0:\n",
    "            return 0\n",
    "\n",
    "        severity = diseased_area / total_leaf\n",
    "        print(f\"🔬 Estimated Severity: {severity:.2%}\")\n",
    "\n",
    "        # Optional: Show mask results\n",
    "        plt.subplot(1, 3, 1), plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)), plt.title('Original')\n",
    "        plt.subplot(1, 3, 2), plt.imshow(leaf_mask, cmap='gray'), plt.title('Leaf Mask')\n",
    "        plt.subplot(1, 3, 3), plt.imshow(disease_in_leaf, cmap='hot'), plt.title('Disease Mask')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        return severity\n",
    "    except Exception as e:\n",
    "        print(f\"Error estimating severity: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Full Pipeline to Classify Disease and Estimate Severity ---\n",
    "def classify_and_estimate_severity(img_path):\n",
    "    if rf_model is None or class_names is None:\n",
    "        print(\"Error: Pre-trained models or class names not loaded properly. Cannot classify disease.\")\n",
    "        return None, None, None\n",
    "\n",
    "    # Step 1: Classify disease using CNN + RF\n",
    "    features = extract_feature_from_image(img_path)\n",
    "    if features is None:\n",
    "        return None, None, None\n",
    "\n",
    "    try:\n",
    "        disease_pred = rf_model.predict([features])[0]\n",
    "        disease_label = class_names[disease_pred]\n",
    "    except Exception as e:\n",
    "        print(f\"Error during disease prediction: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "    # Step 2: Estimate severity using image processing\n",
    "    severity_score = estimate_severity(img_path)\n",
    "    if severity_score is None:\n",
    "        return disease_label, None, None\n",
    "\n",
    "    severity_level = (\n",
    "        \"Mild\" if severity_score < 0.2 else\n",
    "        \"Moderate\" if severity_score < 0.5 else\n",
    "        \"Severe\"\n",
    "    )\n",
    "\n",
    "    # Final Output\n",
    "    print(f\"🌿 Predicted Disease: {disease_label}\")\n",
    "    print(f\"🩺 Estimated Severity: {severity_score:.2%} ({severity_level})\")\n",
    "\n",
    "    return disease_label, severity_level, severity_score\n",
    "\n",
    "# --- Integration with OpenRouter API for Recommendations ---\n",
    "# Replace with your OpenRouter API key\n",
    "OPENROUTER_API_KEY = \"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\"\n",
    "\n",
    "def get_openrouter_recommendation(disease_type, severity):\n",
    "    api_url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # You can experiment with different models available on OpenRouter\n",
    "    # Check https://openrouter.ai/docs#models for a list\n",
    "    model_name = \"mistralai/mistral-medium\"  # Example model\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Provide detailed care and precaution recommendations for the soybean disease '{disease_type}' with '{severity}' severity, considering agricultural practices in Maharashtra, India.\n",
    "    Consider factors like:\n",
    "    - Immediate actions to take.\n",
    "    - Preventative measures for the future.\n",
    "    - Potential environmental considerations specific to the region.\n",
    "    - Best practices for managing this specific disease and severity level.\n",
    "    \"\"\"\n",
    "\n",
    "    payload = json.dumps({\n",
    "        \"model\": model_name,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"max_tokens\": 300,  # Adjust as needed\n",
    "        \"temperature\": 0.7  # Adjust for creativity vs. consistency\n",
    "    })\n",
    "\n",
    "    try:\n",
    "        response = requests.post(api_url, headers=headers, data=payload)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "        response_json = response.json()\n",
    "        if response_json and \"choices\" in response_json and len(response_json[\"choices\"]) > 0:\n",
    "            return response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "        else:\n",
    "            return \"Could not extract a recommendation from the OpenRouter response.\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Error communicating with OpenRouter API: {e}\"\n",
    "    except json.JSONDecodeError:\n",
    "        return \"Error decoding JSON response from OpenRouter.\"\n",
    "\n",
    "# --- Integrated Function to Get Classification, Severity, and Recommendations ---\n",
    "def full_pipeline_with_recommendation(img_path):\n",
    "    disease, severity_level, severity_score = classify_and_estimate_severity(img_path)\n",
    "\n",
    "    if disease and severity_level:\n",
    "        print(\"\\n--- Recommendations from OpenRouter ---\")\n",
    "        recommendations = get_openrouter_recommendation(disease, severity_level)\n",
    "        print(recommendations)\n",
    "    elif disease:\n",
    "        print(\"\\n--- Recommendations cannot be generated as severity estimation failed. ---\")\n",
    "    else:\n",
    "        print(\"\\n--- Disease classification failed. Cannot provide recommendations. ---\")\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = \"D:\\SoySoy\\SoyBean\\Test\\septoria.jpeg\"\n",
    "    full_pipeline_with_recommendation(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File opened successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open('D:\\\\SoySoy\\\\SoyBean\\\\Models\\\\rf_model.pkl', 'rb') as f:\n",
    "        print(\"File opened successfully.\")\n",
    "except OSError as e:\n",
    "    print(f\"Error opening file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
